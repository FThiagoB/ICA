{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0a90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "from classificadores import PerceptronSimples, MultiLayerPerceptron\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9b4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(instâncias=569, features=30, classes=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'M', 1: 'B'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conjunto de dados Câncer de Mama =================================================\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\wdbc.data\", \n",
    "    label_column = 1,\n",
    "    delimiter = \",\",  \n",
    "    column_names = [\"ID\", \"Diagnosis\", \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\", \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\", \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\", \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\", \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\", \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"]\n",
    ").ensure_numeric_labels().remove_features([\"ID\"]).normalize()\n",
    "\n",
    "print(dataset)\n",
    "dataset._label_index_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ef17ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(instâncias=310, features=6, classes=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'DH', 1: 'SL', 2: 'NO'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conjunto de dados Coluna Vertebral =================================================\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\column_3C.dat\", \n",
    "    label_column = -1,\n",
    "    delimiter = \" \",  \n",
    "    column_names = [\"pelvic incidence\", \"pelvic tilt\", \"lumbar lordosis angle\", \"sacral slope\", \"pelvic radius\", \"degree spondylolisthesis\", \"class\"]\n",
    ").ensure_numeric_labels().normalize()\n",
    "\n",
    "print(dataset)\n",
    "dataset._label_index_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265039c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic incidence</th>\n",
       "      <th>pelvic tilt</th>\n",
       "      <th>lumbar lordosis angle</th>\n",
       "      <th>sacral slope</th>\n",
       "      <th>pelvic radius</th>\n",
       "      <th>degree spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.288580</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>-0.541614</td>\n",
       "      <td>-0.498242</td>\n",
       "      <td>-0.385095</td>\n",
       "      <td>-0.949674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.750965</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.802756</td>\n",
       "      <td>-0.710716</td>\n",
       "      <td>-0.046564</td>\n",
       "      <td>-0.927281</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.176698</td>\n",
       "      <td>0.027867</td>\n",
       "      <td>-0.354036</td>\n",
       "      <td>-0.384786</td>\n",
       "      <td>-0.227659</td>\n",
       "      <td>-0.964944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.167631</td>\n",
       "      <td>0.114684</td>\n",
       "      <td>-0.457491</td>\n",
       "      <td>-0.421247</td>\n",
       "      <td>-0.316271</td>\n",
       "      <td>-0.896322</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.545525</td>\n",
       "      <td>-0.421222</td>\n",
       "      <td>-0.743691</td>\n",
       "      <td>-0.506015</td>\n",
       "      <td>-0.180772</td>\n",
       "      <td>-0.911639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>-0.580440</td>\n",
       "      <td>-0.279385</td>\n",
       "      <td>-0.606229</td>\n",
       "      <td>-0.612808</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>-0.968296</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-0.463927</td>\n",
       "      <td>-0.025723</td>\n",
       "      <td>-0.727582</td>\n",
       "      <td>-0.632612</td>\n",
       "      <td>-0.047424</td>\n",
       "      <td>-0.950466</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-0.319059</td>\n",
       "      <td>0.044659</td>\n",
       "      <td>-0.424199</td>\n",
       "      <td>-0.530261</td>\n",
       "      <td>0.195612</td>\n",
       "      <td>-0.961127</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-0.631559</td>\n",
       "      <td>-0.455520</td>\n",
       "      <td>-0.506354</td>\n",
       "      <td>-0.570794</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>-0.947533</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-0.851659</td>\n",
       "      <td>-0.584852</td>\n",
       "      <td>-0.594774</td>\n",
       "      <td>-0.714973</td>\n",
       "      <td>0.158619</td>\n",
       "      <td>-0.949441</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pelvic incidence  pelvic tilt  lumbar lordosis angle  sacral slope  \\\n",
       "0           -0.288580     0.039657              -0.541614     -0.498242   \n",
       "1           -0.750965    -0.406574              -0.802756     -0.710716   \n",
       "2           -0.176698     0.027867              -0.354036     -0.384786   \n",
       "3           -0.167631     0.114684              -0.457491     -0.421247   \n",
       "4           -0.545525    -0.421222              -0.743691     -0.506015   \n",
       "..                ...          ...                    ...           ...   \n",
       "305         -0.580440    -0.279385              -0.606229     -0.612808   \n",
       "306         -0.463927    -0.025723              -0.727582     -0.632612   \n",
       "307         -0.319059     0.044659              -0.424199     -0.530261   \n",
       "308         -0.631559    -0.455520              -0.506354     -0.570794   \n",
       "309         -0.851659    -0.584852              -0.594774     -0.714973   \n",
       "\n",
       "     pelvic radius  degree spondylolisthesis  class  \n",
       "0        -0.385095                 -0.949674    0.0  \n",
       "1        -0.046564                 -0.927281    0.0  \n",
       "2        -0.227659                 -0.964944    0.0  \n",
       "3        -0.316271                 -0.896322    0.0  \n",
       "4        -0.180772                 -0.911639    0.0  \n",
       "..             ...                       ...    ...  \n",
       "305       0.018819                 -0.968296    2.0  \n",
       "306      -0.047424                 -0.950466    2.0  \n",
       "307       0.195612                 -0.961127    2.0  \n",
       "308       0.042478                 -0.947533    2.0  \n",
       "309       0.158619                 -0.949441    2.0  \n",
       "\n",
       "[310 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c339c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic incidence</th>\n",
       "      <th>pelvic tilt</th>\n",
       "      <th>lumbar lordosis angle</th>\n",
       "      <th>sacral slope</th>\n",
       "      <th>pelvic radius</th>\n",
       "      <th>degree spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pelvic incidence</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395875</td>\n",
       "      <td>0.514499</td>\n",
       "      <td>0.664158</td>\n",
       "      <td>0.061248</td>\n",
       "      <td>0.407979</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pelvic tilt</th>\n",
       "      <td>0.395875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187282</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.158277</td>\n",
       "      <td>0.044820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lumbar lordosis angle</th>\n",
       "      <td>0.514499</td>\n",
       "      <td>0.187282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358069</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.284798</td>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sacral slope</th>\n",
       "      <td>0.664158</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.358069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117064</td>\n",
       "      <td>0.274127</td>\n",
       "      <td>0.014523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pelvic radius</th>\n",
       "      <td>0.061248</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.117064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.055102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree spondylolisthesis</th>\n",
       "      <td>0.407979</td>\n",
       "      <td>0.158277</td>\n",
       "      <td>0.284798</td>\n",
       "      <td>0.274127</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.044820</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.055102</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pelvic incidence  pelvic tilt  \\\n",
       "pelvic incidence                  1.000000     0.395875   \n",
       "pelvic tilt                       0.395875     1.000000   \n",
       "lumbar lordosis angle             0.514499     0.187282   \n",
       "sacral slope                      0.664158     0.003885   \n",
       "pelvic radius                     0.061248     0.001067   \n",
       "degree spondylolisthesis          0.407979     0.158277   \n",
       "class                             0.000845     0.044820   \n",
       "\n",
       "                          lumbar lordosis angle  sacral slope  pelvic radius  \\\n",
       "pelvic incidence                       0.514499      0.664158       0.061248   \n",
       "pelvic tilt                            0.187282      0.003885       0.001067   \n",
       "lumbar lordosis angle                  1.000000      0.358069       0.006459   \n",
       "sacral slope                           0.358069      1.000000       0.117064   \n",
       "pelvic radius                          0.006459      0.117064       1.000000   \n",
       "degree spondylolisthesis               0.284798      0.274127       0.000680   \n",
       "class                                  0.001351      0.014523       0.055102   \n",
       "\n",
       "                          degree spondylolisthesis     class  \n",
       "pelvic incidence                          0.407979  0.000845  \n",
       "pelvic tilt                               0.158277  0.044820  \n",
       "lumbar lordosis angle                     0.284798  0.001351  \n",
       "sacral slope                              0.274127  0.014523  \n",
       "pelvic radius                             0.000680  0.055102  \n",
       "degree spondylolisthesis                  1.000000  0.014286  \n",
       "class                                     0.014286  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.determination_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb303bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(0.0): array([ 1., -1., -1.]),\n",
       " np.float64(1.0): array([-1.,  1., -1.]),\n",
       " np.float64(2.0): array([-1., -1.,  1.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vectorize_labels()\n",
    "dataset.label_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c82f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa o conjunto de dados em treinamento e teste\n",
    "train_dataset, test_dataset = dataset.split()\n",
    "train_dataset : Dataset \n",
    "test_dataset : Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c6d4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtremeLearningMachine:\n",
    "    def __init__( self, train_dataset : Dataset ):\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "        self.q = 4                                  # Número de neurônios ocultos\n",
    "        self.p = train_dataset.features_count + 1   # Número de entradas da rede\n",
    "        self.m = train_dataset.class_count          # Número de classes do dataset\n",
    "        self.N = len(train_dataset)                 # Número de instâncias do conjunto de treino\n",
    "\n",
    "        # Função de ativação\n",
    "        self.phi = lambda u: (1 - np.exp(-u)) / (1 + np.exp(-u))\n",
    "\n",
    "        # Incializa as matrizes de pesos\n",
    "        self.W = np.random.normal( size=(self.q, self.p) )     # Pesos da camada oculta (q x p)\n",
    "        self.M = np.random.normal( size=(self.m, self.q+1) )   # Pesos da camada de saída (m, q+1)\n",
    "\n",
    "    def train( self ):\n",
    "        \n",
    "        Z = np.zeros((self.q+1, self.N))    # Matriz de entradas para a camada de saída de cada amostra (q+1, N)\n",
    "        D = np.zeros((self.m, self.N))      # Matriz dos vetores de saída desejada para cada amostra (m, N)\n",
    "\n",
    "        # Preenche as matrizes com os dados de cada instância de treinamento\n",
    "        for index, *features, classe in self.train_dataset:\n",
    "            # Vetor que representa a classe \n",
    "            real_output = self.train_dataset.encode_label( classe )\n",
    "\n",
    "            X = np.r_[features, -1]     # Vetor de entrada da camada oculta\n",
    "            u = self.W @ X              # Ativação da camada oculta\n",
    "            y = self.phi(u)             # Saída da camada oculta (1xq)\n",
    "\n",
    "            Z[:, index] = np.r_[y, -1]  # Adiciona a saída da camada oculta na coluna adequada da amostra atual\n",
    "            D[:, index] = real_output   # Adiciona o vetor de saída desejada na coluna adequada da amostra atual\n",
    "        \n",
    "        # Atualiza a matriz de pesos de saída \n",
    "        inversa = np.linalg.inv( Z @ Z.T ) # (q+1, q+1)\n",
    "\n",
    "        self.M = (\n",
    "            D @ Z.T     # (m, N) x (N, q+1) = (m, q+1)\n",
    "            @ inversa   # (m, q+1) x (q+1, q+1) = (m, q+1)\n",
    "        )\n",
    "    \n",
    "    def predict( self, features : np.ndarray ) -> Union[float, int]:\n",
    "        # Monta o vetor de entrada\n",
    "        x_bias = np.r_[features, -1]\n",
    "\n",
    "        u = self.W @ x_bias # Ativação de cada neurônio oculto\n",
    "        y = self.phi( u )   # Saída dos neurônios ocultos\n",
    "\n",
    "        z = np.r_[ y, -1 ]  # Prepara as entradas para os neurônios de saída\n",
    "        o = self.M @ z      # Calcula a saída dos neurônios de saída\n",
    "\n",
    "        # Monta um vetor de predição baseado no argmax da saída da rede\n",
    "        predicted_output = -np.ones_like(o)\n",
    "        predicted_output[ np.argmax(o) ] = +1\n",
    "\n",
    "        # Retorna a classe correspondente ao vetor predito pela rede\n",
    "        return self.train_dataset.decode_vector( predicted_output ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 4\n",
    "p = train_dataset.features_count + 1\n",
    "m = train_dataset.class_count\n",
    "N = len(train_dataset)\n",
    "\n",
    "activation = lambda u: (1 - np.exp(-u)) / (1 + np.exp(-u))\n",
    "\n",
    "W = np.random.normal( size=(q, p) )     # Pesos da camada oculta (q x p)\n",
    "M = np.random.normal( size=(m, q+1) )   # Pesos da camada de saída (m, q+1)\n",
    "\n",
    "Z = np.zeros((q+1, N))                  # Matriz de entrada para a camada de saída para cada amostra (q+1, N)\n",
    "D = np.zeros((m, N))                    # Matriz dos vetores de saída desejada para cada amostra (m, N)\n",
    "\n",
    "# Calcula as matrizes para cada amostra de treinamento\n",
    "for index, *features, classe in train_dataset:\n",
    "    # Vetor que representa a classe \n",
    "    real_output = train_dataset.encode_label( classe )\n",
    "\n",
    "    X = np.r_[features, -1]     # Vetor de entrada da camada oculta\n",
    "    u = W @ X                   # Ativação da camada oculta\n",
    "    y = activation(u)           # Saída da camada oculta (1xq)\n",
    "\n",
    "    Z[:, index] = np.r_[y, -1]  # Lembrar de adicionar o -1 do bias\n",
    "    D[:, index] = real_output\n",
    "\n",
    "# Atualiza a matriz de pesos da saída \n",
    "inversa = np.linalg.inv( Z @ Z.T ) # (q+1, q+1)\n",
    "M = (\n",
    "    D @ Z.T         # (m, q+1)\n",
    "      @ inversa     # (m, q+1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23d2e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0: 111 erros.\n",
      "Época 25: 45 erros.\n",
      "Época 50: 39 erros.\n",
      "Época 75: 42 erros.\n",
      "Época 100: 39 erros.\n",
      "Época 125: 37 erros.\n",
      "Época 150: 38 erros.\n",
      "Época 175: 35 erros.\n",
      "Época 200: 31 erros.\n",
      "Época 225: 34 erros.\n",
      "Época 250: 39 erros.\n",
      "Época 275: 36 erros.\n",
      "Época 300: 37 erros.\n",
      "Época 325: 33 erros.\n",
      "Época 350: 32 erros.\n",
      "Época 375: 29 erros.\n",
      "Época 400: 32 erros.\n",
      "Época 425: 35 erros.\n",
      "Época 450: 32 erros.\n",
      "Época 475: 33 erros.\n",
      "Treinamento encerrado com 36 erros após 499 épocas.\n",
      "0] Previu 1.0 e era 1.0 [True]\n",
      "1] Previu 0.0 e era 0.0 [True]\n",
      "2] Previu 1.0 e era 1.0 [True]\n",
      "3] Previu 2.0 e era 2.0 [True]\n",
      "4] Previu 0.0 e era 0.0 [True]\n",
      "5] Previu 0.0 e era 0.0 [True]\n",
      "6] Previu 1.0 e era 1.0 [True]\n",
      "7] Previu 1.0 e era 1.0 [True]\n",
      "8] Previu 1.0 e era 1.0 [True]\n",
      "9] Previu 1.0 e era 1.0 [True]\n",
      "10] Previu 1.0 e era 1.0 [True]\n",
      "11] Previu 1.0 e era 1.0 [True]\n",
      "12] Previu 1.0 e era 1.0 [True]\n",
      "13] Previu 0.0 e era 0.0 [True]\n",
      "14] Previu 0.0 e era 2.0 [False]\n",
      "15] Previu 1.0 e era 1.0 [True]\n",
      "16] Previu 2.0 e era 0.0 [False]\n",
      "17] Previu 1.0 e era 1.0 [True]\n",
      "18] Previu 1.0 e era 1.0 [True]\n",
      "19] Previu 0.0 e era 0.0 [True]\n",
      "20] Previu 0.0 e era 0.0 [True]\n",
      "21] Previu 1.0 e era 1.0 [True]\n",
      "22] Previu 1.0 e era 1.0 [True]\n",
      "23] Previu 2.0 e era 2.0 [True]\n",
      "24] Previu 2.0 e era 2.0 [True]\n",
      "25] Previu 2.0 e era 2.0 [True]\n",
      "26] Previu 2.0 e era 2.0 [True]\n",
      "27] Previu 2.0 e era 2.0 [True]\n",
      "28] Previu 1.0 e era 1.0 [True]\n",
      "29] Previu 1.0 e era 1.0 [True]\n",
      "30] Previu 1.0 e era 1.0 [True]\n",
      "31] Previu 2.0 e era 2.0 [True]\n",
      "32] Previu 1.0 e era 1.0 [True]\n",
      "33] Previu 1.0 e era 1.0 [True]\n",
      "34] Previu 1.0 e era 1.0 [True]\n",
      "35] Previu 1.0 e era 1.0 [True]\n",
      "36] Previu 1.0 e era 1.0 [True]\n",
      "37] Previu 2.0 e era 0.0 [False]\n",
      "38] Previu 2.0 e era 2.0 [True]\n",
      "39] Previu 2.0 e era 2.0 [True]\n",
      "40] Previu 1.0 e era 1.0 [True]\n",
      "41] Previu 1.0 e era 1.0 [True]\n",
      "42] Previu 1.0 e era 1.0 [True]\n",
      "43] Previu 0.0 e era 0.0 [True]\n",
      "44] Previu 0.0 e era 0.0 [True]\n",
      "45] Previu 1.0 e era 2.0 [False]\n",
      "46] Previu 0.0 e era 0.0 [True]\n",
      "47] Previu 2.0 e era 2.0 [True]\n",
      "48] Previu 2.0 e era 0.0 [False]\n",
      "49] Previu 1.0 e era 1.0 [True]\n",
      "50] Previu 0.0 e era 0.0 [True]\n",
      "51] Previu 1.0 e era 1.0 [True]\n",
      "52] Previu 1.0 e era 1.0 [True]\n",
      "53] Previu 2.0 e era 0.0 [False]\n",
      "54] Previu 1.0 e era 1.0 [True]\n",
      "55] Previu 2.0 e era 0.0 [False]\n",
      "56] Previu 1.0 e era 1.0 [True]\n",
      "57] Previu 1.0 e era 1.0 [True]\n",
      "58] Previu 1.0 e era 1.0 [True]\n",
      "59] Previu 1.0 e era 1.0 [True]\n",
      "60] Previu 0.0 e era 0.0 [True]\n",
      "61] Previu 1.0 e era 1.0 [True]\n"
     ]
    }
   ],
   "source": [
    "MLP = MultiLayerPerceptron( train_dataset )\n",
    "MLP.train( 500 )\n",
    "\n",
    "for index, *point_test, classe in test_dataset:\n",
    "    classe_prevista = MLP.predict( point_test )\n",
    "    print(f\"{index}] Previu {classe_prevista} e era {classe} [{classe_prevista == classe}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08dc1211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0: erros: 161\n",
      "Época 25: erros: 75\n",
      "Época 50: erros: 84\n",
      "Época 75: erros: 85\n",
      "Época 100: erros: 72\n",
      "Época 125: erros: 76\n",
      "Época 150: erros: 71\n",
      "Época 175: erros: 70\n",
      "Época 200: erros: 73\n",
      "Época 225: erros: 82\n",
      "Época 250: erros: 74\n",
      "Época 275: erros: 77\n",
      "Época 300: erros: 68\n",
      "Época 325: erros: 74\n",
      "Época 350: erros: 72\n",
      "Época 375: erros: 72\n",
      "Época 400: erros: 62\n",
      "Época 425: erros: 66\n",
      "Época 450: erros: 76\n",
      "Época 475: erros: 73\n",
      "Treinamento encerrado com 70 erros após 499 épocas.\n",
      "0] Previu 1.0 e era 1.0 [True]\n",
      "1] Previu 0.0 e era 0.0 [True]\n",
      "2] Previu 1.0 e era 1.0 [True]\n",
      "3] Previu 2.0 e era 2.0 [True]\n",
      "4] Previu 0.0 e era 0.0 [True]\n",
      "5] Previu 2.0 e era 0.0 [False]\n",
      "6] Previu 1.0 e era 1.0 [True]\n",
      "7] Previu 1.0 e era 1.0 [True]\n",
      "8] Previu 1.0 e era 1.0 [True]\n",
      "9] Previu 1.0 e era 1.0 [True]\n",
      "10] Previu 1.0 e era 1.0 [True]\n",
      "11] Previu 1.0 e era 1.0 [True]\n",
      "12] Previu 1.0 e era 1.0 [True]\n",
      "13] Previu 2.0 e era 0.0 [False]\n",
      "14] Previu 0.0 e era 2.0 [False]\n",
      "15] Previu 1.0 e era 1.0 [True]\n",
      "16] Previu 2.0 e era 0.0 [False]\n",
      "17] Previu 1.0 e era 1.0 [True]\n",
      "18] Previu 1.0 e era 1.0 [True]\n",
      "19] Previu 0.0 e era 0.0 [True]\n",
      "20] Previu 2.0 e era 0.0 [False]\n",
      "21] Previu 1.0 e era 1.0 [True]\n",
      "22] Previu 1.0 e era 1.0 [True]\n",
      "23] Previu 2.0 e era 2.0 [True]\n",
      "24] Previu 2.0 e era 2.0 [True]\n",
      "25] Previu 2.0 e era 2.0 [True]\n",
      "26] Previu 2.0 e era 2.0 [True]\n",
      "27] Previu 2.0 e era 2.0 [True]\n",
      "28] Previu 1.0 e era 1.0 [True]\n",
      "29] Previu 1.0 e era 1.0 [True]\n",
      "30] Previu 1.0 e era 1.0 [True]\n",
      "31] Previu 2.0 e era 2.0 [True]\n",
      "32] Previu 1.0 e era 1.0 [True]\n",
      "33] Previu 1.0 e era 1.0 [True]\n",
      "34] Previu 1.0 e era 1.0 [True]\n",
      "35] Previu 1.0 e era 1.0 [True]\n",
      "36] Previu 1.0 e era 1.0 [True]\n",
      "37] Previu 2.0 e era 0.0 [False]\n",
      "38] Previu 2.0 e era 2.0 [True]\n",
      "39] Previu 2.0 e era 2.0 [True]\n",
      "40] Previu 1.0 e era 1.0 [True]\n",
      "41] Previu 1.0 e era 1.0 [True]\n",
      "42] Previu 1.0 e era 1.0 [True]\n",
      "43] Previu 2.0 e era 0.0 [False]\n",
      "44] Previu 2.0 e era 0.0 [False]\n",
      "45] Previu 2.0 e era 2.0 [True]\n",
      "46] Previu 0.0 e era 0.0 [True]\n",
      "47] Previu 2.0 e era 2.0 [True]\n",
      "48] Previu 2.0 e era 0.0 [False]\n",
      "49] Previu 1.0 e era 1.0 [True]\n",
      "50] Previu 0.0 e era 0.0 [True]\n",
      "51] Previu 1.0 e era 1.0 [True]\n",
      "52] Previu 1.0 e era 1.0 [True]\n",
      "53] Previu 2.0 e era 0.0 [False]\n",
      "54] Previu 1.0 e era 1.0 [True]\n",
      "55] Previu 2.0 e era 0.0 [False]\n",
      "56] Previu 1.0 e era 1.0 [True]\n",
      "57] Previu 1.0 e era 1.0 [True]\n",
      "58] Previu 1.0 e era 1.0 [True]\n",
      "59] Previu 1.0 e era 1.0 [True]\n",
      "60] Previu 0.0 e era 0.0 [True]\n",
      "61] Previu 1.0 e era 1.0 [True]\n"
     ]
    }
   ],
   "source": [
    "PS = PerceptronSimples( train_dataset )\n",
    "PS.train( 500 )\n",
    "\n",
    "for index, *point_test, classe in test_dataset:\n",
    "    classe_prevista = PS.predict( point_test )\n",
    "    print(f\"{index}] Previu {classe_prevista} e era {classe} [{classe_prevista == classe}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89b578",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
