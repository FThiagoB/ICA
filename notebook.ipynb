{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "from classificadores import KNN, DMC, PerceptronSimples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Dermatologia =================================================\n",
    "dataset = Dataset.from_file(\n",
    "    filepath = r\"datasets\\dermatology.data\",\n",
    "    label_column = -1,\n",
    "    column_names = [\"erythema\", \"scaling\", \"definite-borders\", \"itching\", \"koebner\" \"phenomenon\", \"polygonal papules\", \"follicular papules\", \"oral-mucosal involvement\", \"knee elbow involvement\", \"scalp involvement\", \"family history\", \"melanin incontinence\", \"eosinophils in the infiltrate\", \"pnl infiltrate\", \"fibrosis of the papillary dermis\", \"exocytosis\", \"acanthosis\", \"hyperkeratosis\", \"parakeratosis\", \"clubbing of the rete ridges\", \"elongation of the rete ridges\", \"thinning of the suprapapillary epidermis\", \"spongiform pustule\", \"munro microabcess\", \"focal hypergranulosis\", \"disappearance of the granular layer\", \"vacuolisation and damage of the basal layer\", \"spongiosis\", \"saw-tooth appearance of retes\", \"follicular horn plug\", \"perifollicular parakeratosis\", \"inflammatory monoluclear infiltrate\", \"band-like infiltrate\", \"age\", \"class\"]\n",
    ").normalize()\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Vinho =================================================\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\wine.data\", \n",
    "    label_column = 0, \n",
    "    column_names = [\"class\", \"Alcohol\", \"Malicacid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\",\"Proanthocyanins\", \"Color intensity\", \"Hue\", \"0D280 0D315 of diluted wines\", \"Proline\"]\n",
    ").normalize().move_label_to_end()\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eede447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Iris =================================================\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\iris.data\", \n",
    "    label_column = -1, \n",
    "    column_names = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"]\n",
    ").ensure_numeric_labels().normalize()\n",
    "\n",
    "print(dataset)\n",
    "dataset._label_index_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Coluna Vertebral =================================================\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\column_3C.dat\", \n",
    "    label_column = -1,\n",
    "    delimiter = \" \",  \n",
    "    column_names = [\"pelvic incidence\", \"pelvic tilt\", \"lumbar lordosis angle\", \"sacral slope\", \"pelvic radius\", \"degree spondylolisthesis\", \"class\"]\n",
    ").ensure_numeric_labels().normalize()\n",
    "\n",
    "print(dataset)\n",
    "dataset._label_index_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265039c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c339c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.determination_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb303bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.vectorize_labels()\n",
    "dataset.label_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa o conjunto de dados em treinamento e teste\n",
    "train_dataset, test_dataset = dataset.split()\n",
    "train_dataset : Dataset \n",
    "test_dataset : Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185aea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 6                                   # Número de neurônios ocultos\n",
    "m = train_dataset.class_count           # Número de neurônios de saída\n",
    "p = train_dataset.features_count + 1    # Número de entradas da rede\n",
    "eta = 0.1                               # Taxa de aprendizado\n",
    "\n",
    "# Função de ativação usada\n",
    "activation = lambda x: np.tanh(x)\n",
    "ddx_activation = lambda x: 1 - activation(x) ** 2\n",
    "\n",
    "# Inicializa o vetor de pesos dos neurônios ocultos\n",
    "W = np.random.normal( size = (q, p) )\n",
    "\n",
    "# Inicializa o vetor de pesos dos neurônios de saída\n",
    "M = np.random.normal( size = (m, q+1) )\n",
    "\n",
    "# Número de épocas de treinamento\n",
    "max_epocas = 5000\n",
    "\n",
    "# Percorre um número qualquer de épocas\n",
    "for epoca in range( max_epocas ):\n",
    "    total_erros = 0\n",
    "\n",
    "    # Para cada época, embaralha o conjunto de treinamento\n",
    "    shuffled_dataset = train_dataset.shuffle()\n",
    "\n",
    "    # Percorre os exemplos do conjunto de treinamento\n",
    "    for index, *features, classe in shuffled_dataset:\n",
    "        # Vetor que representa a classe \n",
    "        real_output = train_dataset.encode_label( classe )\n",
    "\n",
    "        # Monta o vetor de entrada\n",
    "        X_bias = np.r_[features, -1]\n",
    "\n",
    "        # Sentido direto - cálculo da ativação e a saída de cada camada\n",
    "        U = W @ X_bias          # Ativação de cada neurônio oculto\n",
    "        Y = activation( U )     # Saída dos neurônios ocultos\n",
    "\n",
    "        Z = np.r_[ Y, -1 ]      # Prepara as entradas para os neurônios de saída\n",
    "\n",
    "        A = M @ Z               # Ativação dos neurônio de saída\n",
    "        O = activation ( A )    # Saída da camada de saída\n",
    "\n",
    "        # Sentido inverso - atualização dos pesos das camadas\n",
    "        err = real_output - O \n",
    "\n",
    "        # Verifica se houve erros\n",
    "        if np.any(err != 0):\n",
    "            # atualiza os pesos da camada de saída\n",
    "            delta_output = err * ddx_activation( A )                        # (m x 1)\n",
    "            delta_weights_out = eta * np.outer( delta_output, Z )\n",
    "            M = M + delta_weights_out\n",
    "\n",
    "            # calcula os erros retropagados para a camada oculta oculto\n",
    "            output_weights_no_bias_T = M[:, :-1].T                          # (q x m)\n",
    "            backpropagated_error = output_weights_no_bias_T @ delta_output  # (q x 1)\n",
    "\n",
    "            # atualiza os pesos da camada oculta\n",
    "            delta_hidden = backpropagated_error * ddx_activation(U)\n",
    "            delta_weights_hidden = eta * np.outer( delta_hidden, X_bias )\n",
    "            W = W + delta_weights_hidden\n",
    "\n",
    "        # Monta um vetor de predição baseado no argmax da saída da rede\n",
    "        predicted_class = -np.ones_like(O)\n",
    "        predicted_class[ np.argmax(O) ] = +1\n",
    "\n",
    "        if np.argmax(O) != np.argmax(real_output):\n",
    "            total_erros += 1\n",
    "\n",
    "    if (epoca% round(max_epocas*0.05)) == 0:\n",
    "        print(f\"Época {epoca}: {total_erros} erros. - saída {predicted_class} [{real_output}]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = PerceptronSimples( train_dataset )\n",
    "PS.train( 500 )\n",
    "\n",
    "for index, *point_test, classe in test_dataset:\n",
    "    classe_prevista = PS.predict( point_test )\n",
    "    print(f\"{index}] Previu {classe_prevista} e era {classe} [{classe_prevista == classe}]\")\n",
    "\n",
    "train_dataset._centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89b578",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
