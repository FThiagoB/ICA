{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "from classificadores import PerceptronSimples, MultiLayerPerceptron, ExtremeLearningMachine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b31f92f",
   "metadata": {},
   "source": [
    "### Conjunto de dados Câncer de Mama\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Câncer de Mama =================================================\n",
    "colunas = [\"ID\", \"Diagnosis\", \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\", \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\", \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\", \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\", \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\", \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"]\n",
    "\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\wdbc.data\", \n",
    "    label_column = 1,\n",
    "    delimiter = \",\",  \n",
    "    column_names = colunas\n",
    ").ensure_numeric_labels().remove_features([\"ID\"]).normalize()\n",
    "\n",
    "dataset.vectorize_labels()\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionários para armazenar as acurácias\n",
    "acuracia_teste = {\n",
    "    \"PS\": [], \"MLP\": [], \"ELM\": []\n",
    "}\n",
    "\n",
    "acuracia_treinamento = {\n",
    "    \"PS\": [], \"MLP\": [], \"ELM\": []\n",
    "}\n",
    "\n",
    "# Dicionários com as matrizes de confusão\n",
    "matriz_confusão_treinamento = {\n",
    "    \"PS\":  np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"MLP\": np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"ELM\": np.zeros( shape = (dataset.class_count, dataset.class_count) )\n",
    "}\n",
    "\n",
    "matriz_confusão_teste = {\n",
    "    \"PS\":  np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"MLP\": np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"ELM\": np.zeros( shape = (dataset.class_count, dataset.class_count) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef9410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorre as rodada independentes\n",
    "nRodadas = 50\n",
    "\n",
    "for rodada in range( nRodadas ):\n",
    "    print(f\"\\n==== ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== {rodada+1}/{nRodadas}\")\n",
    "\n",
    "    # Para cada rodada independente, realiza o shuffle e separa o conjunto de dados\n",
    "    shuffled_dataset = dataset.shuffle()\n",
    "    train_dataset, test_dataset = shuffled_dataset.split()\n",
    "\n",
    "    # Cria instâncias para os classificadores\n",
    "    PS = PerceptronSimples( train_dataset )\n",
    "    MLP = MultiLayerPerceptron( train_dataset, q = 10 )\n",
    "    ELM = ExtremeLearningMachine( train_dataset, q = 300 )\n",
    "\n",
    "    # Treina cada uma das redes\n",
    "    print(\"Treinando o PS:\")\n",
    "    PS.train( max_epocas = 300, eta = 0.0001 )\n",
    "\n",
    "    print(\"\\nTreinando o MLP:\")\n",
    "    MLP.train( max_epocas = 500, eta = 0.001 )\n",
    "\n",
    "    print(\"\\nTreinando o ELM\")\n",
    "    ELM.train()\n",
    "\n",
    "    # Reseta os erros em cada rodada\n",
    "    erros_treinamento = {\n",
    "        \"PS\": 0, \"MLP\": 0, \"ELM\": 0\n",
    "    }\n",
    "\n",
    "    erros_teste = {\n",
    "        \"PS\": 0, \"MLP\": 0, \"ELM\": 0\n",
    "    }    \n",
    "\n",
    "    #  Percorre o conjunto de treinamento e computa os erros\n",
    "    for index, *features, classe_correta in train_dataset:\n",
    "\n",
    "        # Preenche os dicionários de erros e as matrizes de confusão\n",
    "        for nome, classificador in [(\"PS\", PS), (\"MLP\", MLP), (\"ELM\", ELM)]:\n",
    "            classe_predita = classificador.predict( features )\n",
    "            if classe_predita != classe_correta:\n",
    "                erros_treinamento[ nome ] += 1\n",
    "        \n",
    "            matriz_confusão_treinamento[nome][int(classe_predita)][int(classe_correta)] += 1\n",
    "\n",
    "    # Percorre o conjunto de teste e computa os erros\n",
    "    for index, *features, classe_correta in test_dataset:\n",
    "\n",
    "        # Preenche os dicionários de erros e as matrizes de confusão\n",
    "        for nome, classificador in [(\"PS\", PS), (\"MLP\", MLP), (\"ELM\", ELM)]:\n",
    "            classe_predita = classificador.predict( features )\n",
    "            if classe_predita != classe_correta:\n",
    "                erros_teste[nome] += 1\n",
    "\n",
    "            matriz_confusão_teste[nome][int(classe_predita)][int(classe_correta)] += 1\n",
    "\n",
    "    # Armazena a acurácia da rodada\n",
    "    for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "        acuracia_treinamento[classificador].append(\n",
    "            1 - erros_treinamento[classificador] / len(train_dataset)\n",
    "        )\n",
    "\n",
    "        acuracia_teste[classificador].append(\n",
    "            1 - erros_teste[classificador] / len(test_dataset)\n",
    "        )\n",
    "\n",
    "    # Limpa a tela a cada 4 épocas\n",
    "    if rodada%4 == 0:\n",
    "        clear_output( wait=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e75740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treinamento: \")\n",
    "for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "    média = np.mean( acuracia_treinamento[classificador] )\n",
    "    desvio = np.std( acuracia_treinamento[classificador], ddof=0 )\n",
    "\n",
    "    print(f\"{classificador}: {média*100:.2f}%±{desvio*100:.2f}%\")\n",
    "\n",
    "print(\"\\nTeste:\")\n",
    "for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "    média = np.mean( acuracia_teste[classificador] )\n",
    "    desvio = np.std( acuracia_teste[classificador], ddof=0 )\n",
    "\n",
    "    print(f\"{classificador}: {média*100:.2f}%±{desvio*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para um boxplot de acurácia em treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Cada entrada é uma lista com 50 valores de acurácia\n",
    "dados_treino = [\n",
    "    acuracia_treinamento[\"PS\"],\n",
    "    acuracia_treinamento[\"MLP\"],\n",
    "    acuracia_treinamento[\"ELM\"]\n",
    "]\n",
    "\n",
    "plt.boxplot(dados_treino, tick_labels=[\"PS\", \"MLP\", \"ELM\"], showmeans=True)\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Treinamento em 50 Rodadas Independentes\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para um boxplot de acurácia em treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Cada entrada é uma lista com 50 valores de acurácia\n",
    "dados_teste = [\n",
    "    acuracia_teste[\"PS\"],\n",
    "    acuracia_teste[\"MLP\"],\n",
    "    acuracia_teste[\"ELM\"]\n",
    "]\n",
    "\n",
    "plt.boxplot(dados_teste, tick_labels=[\"PS\", \"MLP\", \"ELM\"], showmeans=True)\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Teste em 50 Rodadas Independentes\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de38581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion( matriz_confusão, labels = None, title = \"\", *, ax = None ):\n",
    "    confusion = ConfusionMatrixDisplay( \n",
    "        matriz_confusão, \n",
    "        display_labels = labels \n",
    "    )\n",
    "\n",
    "    confusion.plot(\n",
    "        colorbar=False,                 # Remove a barra de cores\n",
    "        values_format=\".0f\",            # Mostra valores inteiros (sem notação científica),\n",
    "        text_kw={'color': 'black'},      # Define a cor do texto\n",
    "        ax = ax\n",
    "    )\n",
    "\n",
    "    # Remove os blocos coloridos\n",
    "    for im in confusion.ax_.get_images():\n",
    "        im.set_visible(False)\n",
    "\n",
    "    # Cria uma borda usando retângulos\n",
    "    for i in range( matriz_confusão.shape[0] ):\n",
    "        for j in range( matriz_confusão.shape[1] ):\n",
    "            confusion.ax_.add_patch(\n",
    "                Rectangle( (j - 0.5, i-0.5), 1, 1, fill=False, edgecolor=\"black\", linewidth=1 )\n",
    "            )\n",
    "\n",
    "    # Coloca os labels do eixo X para cima\n",
    "    confusion.ax_.xaxis.set_ticks_position(\"top\")\n",
    "    confusion.ax_.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    # Define o rótulo para os eixos\n",
    "    confusion.ax_.set_xlabel(\"Classe Real\", labelpad=15)\n",
    "    confusion.ax_.set_ylabel(\"Classe Predita\", labelpad=15)\n",
    "\n",
    "    # Seta o título\n",
    "    ax.set_title( title, pad=15 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adefc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(7,10))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=1)\n",
    "\n",
    "for index, classificador in enumerate([\"PS\", \"MLP\", \"ELM\"]):\n",
    "    plot_confusion( \n",
    "        matriz_confusão_treinamento[classificador], \n",
    "        dataset._label_index_to_name.values(),\n",
    "        f\"Conjunto de treinamento : {classificador}\",\n",
    "        ax = axs[index][0]\n",
    "    )\n",
    "\n",
    "    plot_confusion( \n",
    "        matriz_confusão_teste[classificador], \n",
    "        dataset._label_index_to_name.values(),\n",
    "        f\"Conjunto de teste : {classificador}\",\n",
    "        ax = axs[index][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab75ec6",
   "metadata": {},
   "source": [
    "### Conjunto de Dados Coluna Vertebral\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Coluna Vertebral =================================================\n",
    "colunas = [\"pelvic incidence\", \"pelvic tilt\", \"lumbar lordosis angle\", \"sacral slope\", \"pelvic radius\", \"degree spondylolisthesis\", \"class\"]\n",
    "\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\column_3C.dat\", \n",
    "    label_column = -1,\n",
    "    delimiter = \" \",  \n",
    "    column_names = colunas\n",
    ").ensure_numeric_labels().normalize()\n",
    "\n",
    "dataset.vectorize_labels()\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionários para armazenar as acurácias\n",
    "acuracia_teste = {\n",
    "    \"PS\": [], \"MLP\": [], \"ELM\": []\n",
    "}\n",
    "\n",
    "acuracia_treinamento = {\n",
    "    \"PS\": [], \"MLP\": [], \"ELM\": []\n",
    "}\n",
    "\n",
    "# Dicionários com as matrizes de confusão\n",
    "matriz_confusão_treinamento = {\n",
    "    \"PS\":  np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"MLP\": np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"ELM\": np.zeros( shape = (dataset.class_count, dataset.class_count) )\n",
    "}\n",
    "\n",
    "matriz_confusão_teste = {\n",
    "    \"PS\":  np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"MLP\": np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"ELM\": np.zeros( shape = (dataset.class_count, dataset.class_count) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e01566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorre as rodada independentes\n",
    "nRodadas = 50\n",
    "\n",
    "for rodada in range( nRodadas ):\n",
    "    print(f\"\\n==== ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== {rodada+1}/{nRodadas}\")\n",
    "\n",
    "    # Para cada rodada independente, realiza o shuffle e separa o conjunto de dados\n",
    "    shuffled_dataset = dataset.shuffle()\n",
    "    train_dataset, test_dataset = shuffled_dataset.split()\n",
    "\n",
    "    # Cria instâncias para os classificadores\n",
    "    PS = PerceptronSimples( train_dataset )\n",
    "    MLP = MultiLayerPerceptron( train_dataset, q = 10 )\n",
    "    ELM = ExtremeLearningMachine( train_dataset, q = 300 )\n",
    "\n",
    "    # Treina cada uma das redes\n",
    "    print(\"Treinando o PS:\")\n",
    "    PS.train( max_epocas = 300, eta = 0.0001 )\n",
    "\n",
    "    print(\"\\nTreinando o MLP:\")\n",
    "    MLP.train( max_epocas = 500, eta = 0.001 )\n",
    "\n",
    "    print(\"\\nTreinando o ELM\")\n",
    "    ELM.train()\n",
    "\n",
    "    # Reseta os erros em cada rodada\n",
    "    erros_treinamento = {\n",
    "        \"PS\": 0, \"MLP\": 0, \"ELM\": 0\n",
    "    }\n",
    "\n",
    "    erros_teste = {\n",
    "        \"PS\": 0, \"MLP\": 0, \"ELM\": 0\n",
    "    }    \n",
    "\n",
    "    #  Percorre o conjunto de treinamento e computa os erros\n",
    "    for index, *features, classe_correta in train_dataset:\n",
    "\n",
    "        # Preenche os dicionários de erros e as matrizes de confusão\n",
    "        for nome, classificador in [(\"PS\", PS), (\"MLP\", MLP), (\"ELM\", ELM)]:\n",
    "            classe_predita = classificador.predict( features )\n",
    "            if classe_predita != classe_correta:\n",
    "                erros_treinamento[ nome ] += 1\n",
    "        \n",
    "            matriz_confusão_treinamento[nome][int(classe_predita)][int(classe_correta)] += 1\n",
    "\n",
    "    # Percorre o conjunto de teste e computa os erros\n",
    "    for index, *features, classe_correta in test_dataset:\n",
    "\n",
    "        # Preenche os dicionários de erros e as matrizes de confusão\n",
    "        for nome, classificador in [(\"PS\", PS), (\"MLP\", MLP), (\"ELM\", ELM)]:\n",
    "            classe_predita = classificador.predict( features )\n",
    "            if classe_predita != classe_correta:\n",
    "                erros_teste[nome] += 1\n",
    "\n",
    "            matriz_confusão_teste[nome][int(classe_predita)][int(classe_correta)] += 1\n",
    "\n",
    "    # Armazena a acurácia da rodada\n",
    "    for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "        acuracia_treinamento[classificador].append(\n",
    "            1 - erros_treinamento[classificador] / len(train_dataset)\n",
    "        )\n",
    "\n",
    "        acuracia_teste[classificador].append(\n",
    "            1 - erros_teste[classificador] / len(test_dataset)\n",
    "        )\n",
    "\n",
    "    # Limpa a tela a cada 4 épocas\n",
    "    if rodada%4 == 0:\n",
    "        clear_output( wait=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treinamento: \")\n",
    "for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "    média = np.mean( acuracia_treinamento[classificador] )\n",
    "    desvio = np.std( acuracia_treinamento[classificador], ddof=0 )\n",
    "\n",
    "    print(f\"{classificador}: {média*100:.2f}%±{desvio*100:.2f}%\")\n",
    "\n",
    "print(\"\\nTeste:\")\n",
    "for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "    média = np.mean( acuracia_teste[classificador] )\n",
    "    desvio = np.std( acuracia_teste[classificador], ddof=0 )\n",
    "\n",
    "    print(f\"{classificador}: {média*100:.2f}%±{desvio*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bcb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para um boxplot de acurácia em treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Cada entrada é uma lista com 50 valores de acurácia\n",
    "dados_treino = [\n",
    "    acuracia_treinamento[\"PS\"],\n",
    "    acuracia_treinamento[\"MLP\"],\n",
    "    acuracia_treinamento[\"ELM\"]\n",
    "]\n",
    "\n",
    "plt.boxplot(dados_treino, tick_labels=[\"PS\", \"MLP\", \"ELM\"], showmeans=True)\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Treinamento em 50 Rodadas Independentes\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para um boxplot de acurácia em treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Cada entrada é uma lista com 50 valores de acurácia\n",
    "dados_teste = [\n",
    "    acuracia_teste[\"PS\"],\n",
    "    acuracia_teste[\"MLP\"],\n",
    "    acuracia_teste[\"ELM\"]\n",
    "]\n",
    "\n",
    "plt.boxplot(dados_teste, tick_labels=[\"PS\", \"MLP\", \"ELM\"], showmeans=True)\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Teste em 50 Rodadas Independentes\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(7,10))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=1)\n",
    "\n",
    "for index, classificador in enumerate([\"PS\", \"MLP\", \"ELM\"]):\n",
    "    plot_confusion( \n",
    "        matriz_confusão_treinamento[classificador], \n",
    "        dataset._label_index_to_name.values(),\n",
    "        f\"Conjunto de treinamento : {classificador}\",\n",
    "        ax = axs[index][0]\n",
    "    )\n",
    "\n",
    "    plot_confusion( \n",
    "        matriz_confusão_teste[classificador], \n",
    "        dataset._label_index_to_name.values(),\n",
    "        f\"Conjunto de teste : {classificador}\",\n",
    "        ax = axs[index][1]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
