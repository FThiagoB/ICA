{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0a90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "from classificadores import PerceptronSimples, MultiLayerPerceptron, ExtremeLearningMachine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b31f92f",
   "metadata": {},
   "source": [
    "### Conjunto de dados Câncer de Mama\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9b4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(instâncias=569, features=30, classes=2)\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de dados Câncer de Mama =================================================\n",
    "colunas = [\"ID\", \"Diagnosis\", \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\", \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\", \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\", \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\", \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\", \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"]\n",
    "\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\wdbc.data\", \n",
    "    label_column = 1,\n",
    "    delimiter = \",\",  \n",
    "    column_names = colunas\n",
    ").ensure_numeric_labels().remove_features([\"ID\"]).normalize()\n",
    "\n",
    "dataset.vectorize_labels()\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf7e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionários para armazenar as acurácias\n",
    "acuracia_teste = {\n",
    "    \"PS\": [], \"MLP\": [], \"ELM\": []\n",
    "}\n",
    "\n",
    "acuracia_treinamento = {\n",
    "    \"PS\": [], \"MLP\": [], \"ELM\": []\n",
    "}\n",
    "\n",
    "# Dicionários com as matrizes de confusão\n",
    "matriz_confusão_treinamento = {\n",
    "    \"PS\":  np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"MLP\": np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"ELM\": np.zeros( shape = (dataset.class_count, dataset.class_count) )\n",
    "}\n",
    "\n",
    "matriz_confusão_teste = {\n",
    "    \"PS\":  np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"MLP\": np.zeros( shape = (dataset.class_count, dataset.class_count) ), \n",
    "    \"ELM\": np.zeros( shape = (dataset.class_count, dataset.class_count) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ef9410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== 22/50\n",
      "Treinando o PS:\n",
      "Treinamento encerrado após 300 épocas. Custo = 0.6620346116123463.\n",
      "\n",
      "Treinando o MLP:\n",
      "Treinamento encerrado após 500 épocas. Custo = 0.07627839173581186.\n",
      "\n",
      "Treinando o ELM\n",
      "Treinamento encerrado. Custo = 0.03722858261333657\n",
      "\n",
      "==== ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== 23/50\n",
      "Treinando o PS:\n",
      "Treinamento encerrado após 300 épocas. Custo = 0.6830904850994379.\n",
      "\n",
      "Treinando o MLP:\n",
      "Época 325 > Custo: 0.06585020793164928\t\t\t\t\t\t\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m PS\u001b[38;5;241m.\u001b[39mtrain( max_epocas \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m, eta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTreinando o MLP:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mMLP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epocas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTreinando o ELM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m ELM\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\fthia\\Desktop\\Inteligência Computacional Aplicada (ICA)\\classificadores.py:332\u001b[0m, in \u001b[0;36mMultiLayerPerceptron.train\u001b[1;34m(self, max_epocas, eta, reset_weights, verbose)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m+\u001b[39m delta_weights_hidden\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;66;03m# Verifica se a previsão seria acertada ou não\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(real_output):\n\u001b[0;32m    333\u001b[0m         total_erros \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Armazena o custo e a época - usado para plotar o gráfico de aprendizado.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1359\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Percorre as rodada independentes\n",
    "nRodadas = 50\n",
    "\n",
    "for rodada in range( nRodadas ):\n",
    "    print(f\"\\n==== ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== {rodada+1}/{nRodadas}\")\n",
    "\n",
    "    # Para cada rodada independente, realiza o shuffle e separa o conjunto de dados\n",
    "    shuffled_dataset = dataset.shuffle()\n",
    "    train_dataset, test_dataset = shuffled_dataset.split()\n",
    "\n",
    "    # Cria instâncias para os classificadores\n",
    "    PS = PerceptronSimples( train_dataset )\n",
    "    MLP = MultiLayerPerceptron( train_dataset, q = 10 )\n",
    "    ELM = ExtremeLearningMachine( train_dataset, q = 300 )\n",
    "\n",
    "    # Treina cada uma das redes\n",
    "    print(\"Treinando o PS:\")\n",
    "    PS.train( max_epocas = 300, eta = 0.0001 )\n",
    "\n",
    "    print(\"\\nTreinando o MLP:\")\n",
    "    MLP.train( max_epocas = 500, eta = 0.001 )\n",
    "\n",
    "    print(\"\\nTreinando o ELM\")\n",
    "    ELM.train()\n",
    "\n",
    "    # Reseta os erros em cada rodada\n",
    "    erros_treinamento = {\n",
    "        \"PS\": 0, \"MLP\": 0, \"ELM\": 0\n",
    "    }\n",
    "\n",
    "    erros_teste = {\n",
    "        \"PS\": 0, \"MLP\": 0, \"ELM\": 0\n",
    "    }    \n",
    "\n",
    "    #  Percorre o conjunto de treinamento e computa os erros\n",
    "    for index, *features, classe_correta in train_dataset:\n",
    "\n",
    "        # Preenche os dicionários de erros e as matrizes de confusão\n",
    "        for nome, classificador in [(\"PS\", PS), (\"MLP\", MLP), (\"ELM\", ELM)]:\n",
    "            classe_predita = classificador.predict( features )\n",
    "            if classe_predita != classe_correta:\n",
    "                erros_treinamento[ nome ] += 1\n",
    "        \n",
    "            matriz_confusão_treinamento[nome][int(classe_predita)][int(classe_correta)] += 1\n",
    "\n",
    "    # Percorre o conjunto de teste e computa os erros\n",
    "    for index, *features, classe_correta in test_dataset:\n",
    "\n",
    "        # Preenche os dicionários de erros e as matrizes de confusão\n",
    "        for nome, classificador in [(\"PS\", PS), (\"MLP\", MLP), (\"ELM\", ELM)]:\n",
    "            classe_predita = classificador.predict( features )\n",
    "            if classe_predita != classe_correta:\n",
    "                erros_teste[nome] += 1\n",
    "\n",
    "            matriz_confusão_teste[nome][int(classe_predita)][int(classe_correta)] += 1\n",
    "\n",
    "    # Armazena a acurácia da rodada\n",
    "    for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "        acuracia_treinamento[classificador].append(\n",
    "            1 - erros_treinamento[classificador] / len(train_dataset)\n",
    "        )\n",
    "\n",
    "        acuracia_teste[classificador].append(\n",
    "            1 - erros_teste[classificador] / len(test_dataset)\n",
    "        )\n",
    "\n",
    "    # Limpa a tela a cada 4 épocas\n",
    "    if rodada%4 == 0:\n",
    "        clear_output( wait=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e75740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treinamento: \")\n",
    "for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "    média = np.mean( acuracia_treinamento[classificador] )\n",
    "    desvio = np.std( acuracia_treinamento[classificador], ddof=0 )\n",
    "\n",
    "    print(f\"{classificador}: {média*100:.2f}%±{desvio*100:.2f}%\")\n",
    "\n",
    "print(\"\\nTeste:\")\n",
    "for classificador in [\"PS\", \"MLP\", \"ELM\"]:\n",
    "    média = np.mean( acuracia_teste[classificador] )\n",
    "    desvio = np.std( acuracia_teste[classificador], ddof=0 )\n",
    "\n",
    "    print(f\"{classificador}: {média*100:.2f}%±{desvio*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para um boxplot de acurácia em treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Cada entrada é uma lista com 50 valores de acurácia\n",
    "dados_treino = [\n",
    "    acuracia_treinamento[\"PS\"],\n",
    "    acuracia_treinamento[\"MLP\"],\n",
    "    acuracia_treinamento[\"ELM\"]\n",
    "]\n",
    "\n",
    "plt.boxplot(dados_treino, tick_labels=[\"PS\", \"MLP\", \"ELM\"], showmeans=True)\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Treinamento em 50 Rodadas Independentes\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para um boxplot de acurácia em treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Cada entrada é uma lista com 50 valores de acurácia\n",
    "dados_teste = [\n",
    "    acuracia_teste[\"PS\"],\n",
    "    acuracia_teste[\"MLP\"],\n",
    "    acuracia_teste[\"ELM\"]\n",
    "]\n",
    "\n",
    "plt.boxplot(dados_teste, tick_labels=[\"PS\", \"MLP\", \"ELM\"], showmeans=True)\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Teste em 50 Rodadas Independentes\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de38581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion( matriz_confusão, labels = None, title = \"\", *, ax = None ):\n",
    "    confusion = ConfusionMatrixDisplay( \n",
    "        matriz_confusão, \n",
    "        display_labels = labels \n",
    "    )\n",
    "\n",
    "    confusion.plot(\n",
    "        colorbar=False,                 # Remove a barra de cores\n",
    "        values_format=\".0f\",            # Mostra valores inteiros (sem notação científica),\n",
    "        text_kw={'color': 'black'},      # Define a cor do texto\n",
    "        ax = ax\n",
    "    )\n",
    "\n",
    "    # Remove os blocos coloridos\n",
    "    for im in confusion.ax_.get_images():\n",
    "        im.set_visible(False)\n",
    "\n",
    "    # Cria uma borda usando retângulos\n",
    "    for i in range( matriz_confusão.shape[0] ):\n",
    "        for j in range( matriz_confusão.shape[1] ):\n",
    "            confusion.ax_.add_patch(\n",
    "                Rectangle( (j - 0.5, i-0.5), 1, 1, fill=False, edgecolor=\"black\", linewidth=1 )\n",
    "            )\n",
    "\n",
    "    # Coloca os labels do eixo X para cima\n",
    "    confusion.ax_.xaxis.set_ticks_position(\"top\")\n",
    "    confusion.ax_.xaxis.set_label_position(\"top\")\n",
    "\n",
    "    # Define o rótulo para os eixos\n",
    "    confusion.ax_.set_xlabel(\"Classe Real\", labelpad=15)\n",
    "    confusion.ax_.set_ylabel(\"Classe Predita\", labelpad=15)\n",
    "\n",
    "    # Seta o título\n",
    "    ax.set_title( title, pad=15 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adefc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(7,10))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=1)\n",
    "\n",
    "for index, classificador in enumerate([\"PS\", \"MLP\", \"ELM\"]):\n",
    "    plot_confusion( \n",
    "        matriz_confusão_treinamento[classificador], \n",
    "        dataset._label_index_to_name.values(),\n",
    "        f\"Conjunto de treinamento : {classificador}\",\n",
    "        ax = axs[index][0]\n",
    "    )\n",
    "\n",
    "    plot_confusion( \n",
    "        matriz_confusão_teste[classificador], \n",
    "        dataset._label_index_to_name.values(),\n",
    "        f\"Conjunto de teste : {classificador}\",\n",
    "        ax = axs[index][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab75ec6",
   "metadata": {},
   "source": [
    "### Conjunto de Dados Coluna Vertebral\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Coluna Vertebral =================================================\n",
    "colunas = [\"pelvic incidence\", \"pelvic tilt\", \"lumbar lordosis angle\", \"sacral slope\", \"pelvic radius\", \"degree spondylolisthesis\", \"class\"]\n",
    "\n",
    "dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\column_3C.dat\", \n",
    "    label_column = -1,\n",
    "    delimiter = \" \",  \n",
    "    column_names = colunas\n",
    ").ensure_numeric_labels().normalize()\n",
    "\n",
    "dataset.vectorize_labels()\n",
    "\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
