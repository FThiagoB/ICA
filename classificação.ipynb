{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados Iris ================================================================================================================\n",
    "iris_dataset = Dataset.from_file( \n",
    "    filepath = r\"datasets\\iris.data\", \n",
    "    label_column = -1, \n",
    "    column_names = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"]\n",
    ").ensure_numeric_labels().normalize()\n",
    "\n",
    "iris_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265039c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c339c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset.determination_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa o conjunto de dados em treinamento e teste\n",
    "train_dataset, test_dataset = iris_dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea138da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_euclidiana( P1 : Union[ np.ndarray, list[float] ], P2 : Union[ np.ndarray, list[float] ] ) -> float:\n",
    "    distance = np.subtract( P1, P2 ) ** 2\n",
    "    distance = np.sqrt( np.sum( distance ) )\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def KNN( train_dataset : Dataset, P : np.ndarray, k : int = 3 ) -> float:\n",
    "    distances = []\n",
    "    classe = None\n",
    "\n",
    "    # Percorre as instâncias de treinamento\n",
    "    for index, *features, classe in train_dataset:\n",
    "        # Armazena o indice do elemento de treinamento e a distância dele até o ponto classificado\n",
    "        distances.append( (index, dist_euclidiana( features, P )) )\n",
    "    \n",
    "    # Ordena a lista em função da distância\n",
    "    distances = sorted( distances, key = lambda el: el[1] )\n",
    "\n",
    "    # Obtém a posição dos k elementos mais próximos\n",
    "    positions = [el[0] for i, el in enumerate(distances) if i < k]\n",
    "\n",
    "    # Obtém a classe dos k elementos mais próximos\n",
    "    classes = train_dataset.y[ positions ].to_numpy()\n",
    "\n",
    "    # Obtém a classe com a maior moda\n",
    "    classes, moda = np.unique( classes, return_counts = True )\n",
    "    classe = classes[ np.argmax(moda) ]\n",
    "    \n",
    "    return classe\n",
    "\n",
    "def DMC( train_dataset : Dataset, P : np.ndarray, k : int = 3 ) -> float:\n",
    "    distances = []\n",
    "    classe = None\n",
    "\n",
    "    # Calcula os centroides das classes\n",
    "    \n",
    "    # Percorre as instâncias de treinamento\n",
    "    for index, *features, classe in train_dataset:\n",
    "        # Armazena o indice do elemento de treinamento e a distância dele até o ponto classificado\n",
    "        distances.append( (index, dist_euclidiana( features, P )) )\n",
    "    \n",
    "    # Ordena a lista em função da distância\n",
    "    distances = sorted( distances, key = lambda el: el[1] )\n",
    "\n",
    "    # Obtém a posição dos k elementos mais próximos\n",
    "    positions = [el[0] for i, el in enumerate(distances) if i < k]\n",
    "\n",
    "    # Obtém a classe dos k elementos mais próximos\n",
    "    classes = train_dataset.y[ positions ].to_numpy()\n",
    "\n",
    "    # Obtém a classe com a maior moda\n",
    "    classes, moda = np.unique( classes, return_counts = True )\n",
    "    classe = classes[ np.argmax(moda) ]\n",
    "    \n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroides = [\n",
    "    np.array( np.mean( train_dataset.X[ train_dataset.y == i ], axis=0 ) ) for i in train_dataset.y.unique()\n",
    "]\n",
    "\n",
    "plt.scatter( train_dataset.X.iloc[:, 2], train_dataset.X.iloc[:, 3], c = train_dataset.y )\n",
    "plt.scatter( centroides[0][2], centroides[0][3], marker=\"x\", c=\"pink\")\n",
    "plt.scatter( centroides[1][2], centroides[1][3], marker=\"x\", c=\"red\")\n",
    "plt.scatter( centroides[2][2], centroides[2][3], marker=\"x\", c=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, *point_test, classe in test_dataset:\n",
    "    classe_prevista = KNN( train_dataset, point_test )\n",
    "    print(f\"{index}] Previu {classe_prevista} e era {classe} [{classe_prevista == classe}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89b578",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
