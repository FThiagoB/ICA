{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0a90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Usado para o método split: é possível fazer um split manualmente, mas train_test_split é mais eficiente e há estratificação já implementada.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f479fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza alguns imports para a especificação de tipos\n",
    "from typing import Self, Optional, Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df82d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__( self, data: pd.DataFrame, *, label_column : int = -1, column_names : Optional[list[str]] = None ) -> None:\n",
    "        \"\"\"\n",
    "        Inicializa a classe Dataset.\n",
    "\n",
    "        Args:\n",
    "            data: DataFrame com os dados do conjunto de dados.\n",
    "            label_column: Posição da coluna de rótulo (por padrão é -1, última coluna).\n",
    "            column_names: Lista opcional com os nomes das colunas.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data                    # Guarda o DataFrame do conjunto de dados\n",
    "        self.label_column = label_column    # Armazena o índice para a coluna de rótulo\n",
    "        self.column_names = column_names    # Armazena a lista com os rótulos das colunas do DataFrame\n",
    "\n",
    "        # Se for especificado, define o nome das colunas\n",
    "        if self.column_names is not None:\n",
    "            self._set_column_names()\n",
    "\n",
    "    def _set_column_names( self ) -> None:\n",
    "        \"\"\"\n",
    "        Atualiza os rótulos das colunas do DataFrame, conforme o valor no atributo column_names.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data.columns = self.column_names\n",
    "\n",
    "    def shuffle( self, random_state: Optional[int] = None ) -> Self:\n",
    "        \"\"\"\n",
    "        Retorna uma nova instância da classe com os dados embaralhados.\n",
    "\n",
    "        Args:\n",
    "            random_state: Semente opcional para reprodução de resultados.\n",
    "        \n",
    "        Returns:\n",
    "            Uma nova instância do Dataset com os dados embaralhados.\n",
    "        \"\"\"\n",
    "\n",
    "        # Obtém um DataFrame embaralhado e com os índices resetados\n",
    "        data = self.data.sample(frac=1, random_state=random_state).reset_index( drop=True )\n",
    "\n",
    "        # Retorna uma nova instância da classe\n",
    "        return self.__class__( data, label_column = self.label_column, column_names = self.column_names )\n",
    "    \n",
    "    def split( self, train_size: int = 0.8, *, random_state: Optional[int] = None, stratify: bool = False ) -> tuple[Self, Self]:\n",
    "        \"\"\"\n",
    "        Divide o Dataset em conjunto de treinamento e de conjunto de teste.\n",
    "\n",
    "        Args:\n",
    "            train_size: Proporção do conjunto de treinamento (0-1).\n",
    "            random_state: Semente opcional para reprodução de resultados.\n",
    "            stratify: Se for True, manterá a proporção entre as classes\n",
    "        \n",
    "        Returns:\n",
    "            Tupla( train_set, test_set )\n",
    "        \"\"\"\n",
    "\n",
    "        # Verifica se stratify foi setado\n",
    "        _stratify = self.y if stratify == True else None\n",
    "\n",
    "        # Separa o conjunto de dados em dois\n",
    "        train, test = train_test_split(\n",
    "            self.data,\n",
    "            train_size = train_size,\n",
    "            random_state = random_state,\n",
    "            stratify = _stratify\n",
    "        )\n",
    "\n",
    "        # Retorna as instâncias para Datasets dos conjuntos separados\n",
    "        return (\n",
    "            self.__class__( train, label_column = self.label_column, column_names = self.column_names ),\n",
    "            self.__class__( test, label_column = self.label_column, column_names = self.column_names )\n",
    "        )\n",
    "    \n",
    "    def remove_features( self, features_to_remove: List[ Union[int, str] ] ) -> Self:\n",
    "        \"\"\" Remove features do conjunto de dados.\n",
    "        \n",
    "        Args:\n",
    "            features_to_remove: Lista de índices (inteiros) ou de nomes das colunas a serem removidas.\n",
    "        \n",
    "        Returns:\n",
    "            Um novo Dataset com as features restantes.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Formatos ou valores inválidos foram especificados em features_to_remove\n",
    "        \"\"\"\n",
    "\n",
    "        # Realiza uma cópia do DataFrame (garante imutabilidade)\n",
    "        new_data = self.data.copy( deep = True )\n",
    "        m, n = new_data.shape\n",
    "\n",
    "        # Índices a serem removidos\n",
    "        cols_to_drop = set()\n",
    "\n",
    "        # Percorre a lista especificada de atributos a serem removidos\n",
    "        for feature in features_to_remove:\n",
    "            # O atributo foi especificado como índice\n",
    "            if isinstance(feature, int):\n",
    "                # Trata índices negativos\n",
    "                idx = feature if feature >= 0 else (feature + n)\n",
    "                \n",
    "                # Verifica se o índice está fora do intervalo permitido\n",
    "                if (idx < 0) or (idx >= n):\n",
    "                    raise ValueError(f\"Índice {feature} fora do intervalo permitido.\")\n",
    "                \n",
    "                cols_to_drop.add( idx )\n",
    "            \n",
    "            # O atributo foi especificado como string\n",
    "            elif isinstance(feature, str):\n",
    "                # Verifica se o atributo column_names está declarado\n",
    "                if not self.column_names:\n",
    "                    raise ValueError(\"Nomes de colunas não definidos.\")\n",
    "                \n",
    "                # Recupera o índice do valor especificado\n",
    "                try:\n",
    "                    idx = self.column_names.index(feature)\n",
    "                \n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"Coluna '{feature}' não encontrada.\")\n",
    "                \n",
    "                cols_to_drop.add(idx)\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(\"Os elementos especificador devem ser str ou int\")\n",
    "        \n",
    "        # Verifica se a coluna de label foi especificada\n",
    "        if ( (self.label_column >= 0) and (self.label_column in cols_to_drop) ) or ( (self.label_column < 0) and ((self.label_column + n) in cols_to_drop) ):\n",
    "            raise ValueError(\"Não é permitido remover a coluna de label\")\n",
    "        \n",
    "        # Calcula as colunas restantes\n",
    "        remaining_cols = [i for i in range(n) if i not in cols_to_drop]\n",
    "\n",
    "        # Atualiza a posição do label = label atual menos a quantidade de atributos anteriores que foram removidos\n",
    "        new_label_column = self.label_column - sum( 1 for col in cols_to_drop if col < self.label_column )\n",
    "\n",
    "        # Atualiza a lista de nomes, se estiver definida\n",
    "        remaining_label_column = None\n",
    "\n",
    "        if self.column_names:\n",
    "            remaining_label_column = [label for i, label in enumerate(self.column_names) if i not in cols_to_drop]\n",
    "\n",
    "        # Atualiza o DataFrame para as colunas restantes\n",
    "        new_data = new_data.iloc[:, remaining_cols]\n",
    "        \n",
    "        # Retorna uma nova instância para Dataset com os atributos restantes\n",
    "        return self.__class__( new_data, label_column = new_label_column, column_names = remaining_label_column )\n",
    "\n",
    "    def normalize( self ) -> Self:\n",
    "        \"\"\" Retorna o conjunto de dados com atributos normalizados em [-1, +1] \"\"\"\n",
    "        m, n, k = self.shape                        # Dimensões do Dataset\n",
    "        new_data = self.data.copy( deep = True )    # Cópia do conjunto de dados\n",
    "\n",
    "        # Percorre os índices dos atributos\n",
    "        for idx in range( n ):\n",
    "            # Obtém o subconjunto do atributo de índice idx\n",
    "            column = new_data.iloc[:, idx]\n",
    "\n",
    "            # Obtém os valores de mínimo e máximo do subconjunto\n",
    "            _min = np.min( column )\n",
    "            _max = np.max( column )\n",
    "            \n",
    "            # Subconjunto normalizado\n",
    "            new_column = 2 * (column - _min) / (_max - _min) - 1\n",
    "\n",
    "            # Ataliza o conjunto de dados com o subconjunto normalizado\n",
    "            new_data.iloc[:, idx] = new_column\n",
    "        \n",
    "        # Retorna uma nova instância normalizada\n",
    "        return self.__class__( new_data, label_column = self.label_column, column_names = self.column_names )\n",
    "\n",
    "    @classmethod\n",
    "    def from_file( cls, filepath : str, *, comment_marker : str = \"#\", missing_marker : str = \"?\", label_column : int = -1, column_names : Optional[list[str]] = None ) -> None:\n",
    "        \"\"\"\n",
    "        Inicializa a classe a partir de um arquivo CSV.\n",
    "\n",
    "        Args:\n",
    "            filepath: Caminho para o arquivo CSV.\n",
    "            comment_marker: Marcador para linhas de comentário (serão ignoradas).\n",
    "            missing_marker: Marcador para elementos faltantes (substituídos por NaN).\n",
    "            Posição da coluna de rótulo (por padrão é -1, última coluna).\n",
    "            column_names: Lista opcional com o nome das colunas.\n",
    "        \"\"\"\n",
    "\n",
    "        # Lê o arquivo CSV (Não existe linhas de header no arquivo)\n",
    "        data = pd.read_csv( filepath, header=None, comment=comment_marker, na_values=missing_marker )\n",
    "\n",
    "        # Remover elementos faltantes\n",
    "        data = data.dropna()\n",
    "\n",
    "        # Retorna uma chamada para o construtor normal da classe\n",
    "        return cls( data, label_column = label_column, column_names = column_names )\n",
    "    \n",
    "    @property\n",
    "    def X( self ) -> pd.DataFrame:\n",
    "        \"\"\" Retorna as colunas de atributos \"\"\"\n",
    "\n",
    "        # Caso mais simples, a coluna de label está no final\n",
    "        if self.label_column == -1:\n",
    "            return self.data.iloc[:, :self.label_column]\n",
    "        \n",
    "        # Se a coluna de resultados estiver em uma posição diferente da coluna final, compõe o DataFrame com os atributos\n",
    "        return pd.concat([\n",
    "            self.data.iloc[:, :self.label_column],  \n",
    "            self.data.iloc[:, self.label_column+1:]\n",
    "        ], axis=1 )        \n",
    "    \n",
    "    @property\n",
    "    def y( self ) -> pd.Series:\n",
    "        \"\"\" Retorna a coluna de rótulo \"\"\"\n",
    "\n",
    "        return self.data.iloc[:, self.label_column]\n",
    "    \n",
    "    @property\n",
    "    def shape( self ) -> tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        Retorna as dimensões do Dataset\n",
    "\n",
    "        Returns:\n",
    "            Tupla[m, n, k] onde:\n",
    "            m = número de instâncias\n",
    "            n = número de atributos \n",
    "            k = número de classes\n",
    "        \"\"\"\n",
    "\n",
    "        m, n = self.data.shape\n",
    "        k = len( self.y.unique() )\n",
    "\n",
    "        # A coluna de rótulo está contada em n\n",
    "        return (m, n-1, k)\n",
    "    \n",
    "    def __len__( self ):\n",
    "        \"\"\" Retorna o número de instâncias do conjunto de dados. \"\"\"\n",
    "        return len( self.data )\n",
    "    \n",
    "    def __repr__( self ):\n",
    "        \"\"\" Retorna uma string representando o objeto. \"\"\"\n",
    "        m, n, k = self.shape\n",
    "        return f\"Dataset(instâncias={m}, features={n}, classes={k})\"\n",
    "    \n",
    "    def __iter__( self ):\n",
    "        \"\"\" Retorna o objeto iterável da classe \"\"\"\n",
    "        return self.data.itertuples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ff279ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = r\"datasets\\iris.data\"    # caminho do arquivo\n",
    "column_names = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"] # Nome dos campos\n",
    "\n",
    "data = Dataset.from_file( path_dataset, label_column=-1, column_names=column_names ).normalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
